{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logical Progression ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 -m pip install --upgrade pip && pip install -q -r requirements.txt\n",
      "Requirement already satisfied: pip in /Users/iolanigan/LangChain/.venv/lib/python3.10/site-packages (23.2.1)\n"
     ]
    }
   ],
   "source": [
    "# Install Dependencies\n",
    "!make install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"docs/LPYear1-10.pdf\"\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6870"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بسم الله الرحمن الرحٌم  \n",
      " \n",
      "الحمد لله رب العالمٌن  \n",
      " \n",
      "اللهم صلً وسلم وبارك على نبٌنا محمد وعلى صحبه أجمعٌن  \n",
      " \n",
      "اللهُمَّ لا سَهْلَ إلا مَا جَعَلتَهُ سَهْلا وَ أنتَ تَجْعَلُ الحزْنَ إذا شِئْتَ سَهْلا \n",
      " \n",
      "اللهم أعنا على ذكرك وشكرك وحسن عبادتك ٌا رب الكرٌم  \n",
      " \n",
      "We begin with the name of Allāh (sub ḥānahu wa taʿāla),  we praise Him , and we hope that He will help \n",
      "us remember Him, we hope that He will help us thank Him --because we’re pretty bad at that, to be \n",
      "honest , when left to our own devices --an\n"
     ]
    }
   ],
   "source": [
    "print(pages[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cited in the prayer,  after the prayer as well, and in \n",
      "general, when one feels the need.  \n",
      " \n",
      "I ask Allāh (sub ḥānahu wa taʿāla)  to make this easy. There is no ease, and nothing happens except by His\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[-200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19856"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "rdocs = rec_splitter.split_documents(pages)\n",
    "len(rdocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cite from the Qur ʾān so that we can hopefully start this journey  with so me \n",
      "barakah, and some ayā t which I think are very pertinent to the reason why we’re here, what the goa l of \n",
      "the journey is.\n"
     ]
    }
   ],
   "source": [
    "print(rdocs[0].page_content[-200:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iolanigan/LangChain/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)cb085/.gitattributes: 100%|██████████| 1.63k/1.63k [00:00<00:00, 9.35MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 201/201 [00:00<00:00, 253kB/s]\n",
      "Downloading (…)cd0eacb085/README.md: 100%|██████████| 160k/160k [00:00<00:00, 3.64MB/s]\n",
      "Downloading (…)0eacb085/config.json: 100%|██████████| 690/690 [00:00<00:00, 4.89MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 2.24G/2.24G [03:24<00:00, 11.0MB/s]\n",
      "Downloading (…)085/onnx/config.json: 100%|██████████| 688/688 [00:00<00:00, 1.72MB/s]\n",
      "Downloading model.onnx: 100%|██████████| 546k/546k [00:00<00:00, 8.99MB/s]\n",
      "Downloading model.onnx_data: 100%|██████████| 2.24G/2.24G [03:23<00:00, 11.0MB/s]\n",
      "Downloading (…)tencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:00<00:00, 10.5MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 280/280 [00:00<00:00, 965kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 17.1M/17.1M [00:01<00:00, 11.2MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 418/418 [00:00<00:00, 734kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 2.24G/2.24G [03:25<00:00, 10.9MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 57.0/57.0 [00:00<00:00, 85.6kB/s]\n",
      "Downloading (…)tencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:00<00:00, 10.8MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 280/280 [00:00<00:00, 481kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 17.1M/17.1M [00:01<00:00, 11.2MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 418/418 [00:00<00:00, 1.29MB/s]\n",
      "Downloading (…)eacb085/modules.json: 100%|██████████| 387/387 [00:00<00:00, 705kB/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"intfloat/multilingual-e5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = 'db/chroma/'\n",
    "!rm -rf ./db/chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_name = \"intfloat/multilingual-e5-large\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(\"lp_store\", embedding)\n",
    "# vectordb = Chroma.from_documents(\n",
    "#     documents=rdocs,\n",
    "#     embedding=embedding,\n",
    "#     persist_directory=persist_directory\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.add_documents(rdocs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
